var documenterSearchIndex = {"docs":
[{"location":"omegavsotherppls/#Omega-vs-other-Probabilistic-Programming-Languages","page":"Omega vs other PPLs","title":"Omega vs other Probabilistic Programming Languages","text":"","category":"section"},{"location":"omegavsotherppls/","page":"Omega vs other PPLs","title":"Omega vs other PPLs","text":"There are many probabilistic programming languages and libraries. The objective of Omega is to increase the expressiveness of probabilistic programming languages.  There are models and inference queries that are either impossible or very difficult to express in other PPLs.  In particular:","category":"page"},{"location":"omegavsotherppls/","page":"Omega vs other PPLs","title":"Omega vs other PPLs","text":"In Omega you condition on predicates\nOmega supports likelihood free inference\nOmega supports causal inference\nOmega is fast (and type stable)","category":"page"},{"location":"omegavsotherppls/#Omega-vs-...","page":"Omega vs other PPLs","title":"Omega vs ...","text":"","category":"section"},{"location":"omegavsotherppls/","page":"Omega vs other PPLs","title":"Omega vs other PPLs","text":"Turing: Omega does not yet suport likelihood based inference, although it is planned, so use Turing if that is the case.  Turing currently has more infernece procedures implemented. Omega is more flexible, likely faster, and supports causal and distributional inference.\nStan: Use Stan if you model is expressible in stan, i.e.,  differentiable and of finite dimension.  Otherwise, consider Omega.\nPyro, TensorFlow Probability: Omega does not yet support variational inference (contributions welcome!), so use those frameworks if that is required.","category":"page"},{"location":"advancedtutorial/#Advanced-Tutorial","page":"Advanced Tutorial","title":"Advanced Tutorial","text":"","category":"section"},{"location":"advancedtutorial/","page":"Advanced Tutorial","title":"Advanced Tutorial","text":"A more advanced tutorial","category":"page"},{"location":"distributions/#Built-In-Distributions","page":"Built-in Distributions","title":"Built In Distributions","text":"","category":"section"},{"location":"distributions/","page":"Built-in Distributions","title":"Built-in Distributions","text":"Omega comes with a number of built-in probability distributions.","category":"page"},{"location":"distributions/#Univariate-Distributions","page":"Built-in Distributions","title":"Univariate Distributions","text":"","category":"section"},{"location":"distributions/","page":"Built-in Distributions","title":"Built-in Distributions","text":"bernoulli\nbetarv\ncategorical\nconstant\nexponential\ngammarv\ninvgamma\nkumaraswamy\nlogistic\npoisson\nnormal\nuniform\nrademacher","category":"page"},{"location":"distributions/#Multivariate-Distributions","page":"Built-in Distributions","title":"Multivariate Distributions","text":"","category":"section"},{"location":"distributions/","page":"Built-in Distributions","title":"Built-in Distributions","text":"mvnormal\ndirichlet","category":"page"},{"location":"distributions/#Describe-distributional-functions","page":"Built-in Distributions","title":"Describe distributional functions","text":"","category":"section"},{"location":"distributions/","page":"Built-in Distributions","title":"Built-in Distributions","text":"Omega comes with some functions which summarize an entire distribution. Most of these are inherited from Distributions.jl","category":"page"},{"location":"distributions/","page":"Built-in Distributions","title":"Built-in Distributions","text":"mean\nprob","category":"page"},{"location":"conditionalindependence/#Conditional-Independence","page":"(Conditional) Independence","title":"Conditional Independence","text":"","category":"section"},{"location":"conditionalindependence/","page":"(Conditional) Independence","title":"(Conditional) Independence","text":"note: Note\nA class in Omega is similar to a \"plate\" in Bayesian networks.```","category":"page"},{"location":"conditionalindependence/","page":"(Conditional) Independence","title":"(Conditional) Independence","text":"A class in Omega is a function of the form f(id, \\omega). It represents a sequence of random variables in the sense that ... To get the nth member of a class use the function nth.","category":"page"},{"location":"conditionalindependence/","page":"(Conditional) Independence","title":"(Conditional) Independence","text":"There are primitive random variable classes in Omega.","category":"page"},{"location":"conditionalindependence/","page":"(Conditional) Independence","title":"(Conditional) Independence","text":"A1 = nth(StdNormal, 1)\nA2 = nth(StdNormal, 2)\nA3 = nth(StdNormal, 3)","category":"page"},{"location":"conditionalindependence/","page":"(Conditional) Independence","title":"(Conditional) Independence","text":"Or equivalently, use ~:","category":"page"},{"location":"conditionalindependence/","page":"(Conditional) Independence","title":"(Conditional) Independence","text":"A1 = 1 ~ StdNormal, 1\nA2 = 2 ~ StdNormal, 2\nA3 = 3 ~ StdNormal, 3","category":"page"},{"location":"conditionalindependence/","page":"(Conditional) Independence","title":"(Conditional) Independence","text":"Of course, you can specify your own classes simply by constructing a function. In ","category":"page"},{"location":"conditionalindependence/","page":"(Conditional) Independence","title":"(Conditional) Independence","text":"using Omega, Distributions\nμ = 1 ~ StdNormal{Float64}()\nfunction Xs(id, ω)\n  id ~ Normal(ω, μ(ω), 1) \nend\nx1 = 1 ~ Xs\nx2 = 2 ~ Xs","category":"page"},{"location":"conditionalindependence/","page":"(Conditional) Independence","title":"(Conditional) Independence","text":"To construct a random variable over collections from a class, use Mv ","category":"page"},{"location":"conditionalindependence/","page":"(Conditional) Independence","title":"(Conditional) Independence","text":"A very important property of classes is that the members of a class are conditionally independent, given the shared parents. In the above exmaple, x1 and x2 are conditionally independent given μ.","category":"page"},{"location":"conditionalindependence/","page":"(Conditional) Independence","title":"(Conditional) Independence","text":"ciid","category":"page"},{"location":"conditionalindependence/#Independence","page":"(Conditional) Independence","title":"Independence","text":"","category":"section"},{"location":"conditionalindependence/","page":"(Conditional) Independence","title":"(Conditional) Independence","text":"Sometimes we need to construct random variables that are independent.  The function iid constructs a class of random variables that are independent.","category":"page"},{"location":"basiccausal/#Counterfactuals","page":"Tutorial","title":"Counterfactuals","text":"","category":"section"},{"location":"basiccausal/","page":"Tutorial","title":"Tutorial","text":"The utility of replace may not be obvious at first glance. We can use replace and cond separately and in combination to ask lots of different kinds of questions. In this example, we model the relationship betwee the weather outside and teh thermostat reading inside a house. Broadly, the model says that the weather outside is dictataed by the time of day, while the temperature inside is determined by whether the air conditioning is on, and whether the window is open.","category":"page"},{"location":"basiccausal/","page":"Tutorial","title":"Tutorial","text":"Notebook","category":"page"},{"location":"basiccausal/","page":"Tutorial","title":"Tutorial","text":"First, setup simple priors over the time of day, and variables to determine whether the air conditioning is on and whether hte iwndow is open:","category":"page"},{"location":"basiccausal/","page":"Tutorial","title":"Tutorial","text":"timeofday = uniform([:morning, :afternoon, :evening])\nis_window_open = bernoulli(0.5)\nis_ac_on = bernoulli(0.3)","category":"page"},{"location":"basiccausal/","page":"Tutorial","title":"Tutorial","text":"Second, assume that the outside temperature depends on the time of day, being hottest in the afternoon, but cold at night:","category":"page"},{"location":"basiccausal/","page":"Tutorial","title":"Tutorial","text":"function outside_temp_(rng)\n  if timeofday(rng) == :morning\n    normal(rng, 20.0, 1.0)\n  elseif timeofday(rng) == :afternoon\n    normal(rng, 32.0, 1.0)\n  else\n    normal(rng, 10.0, 1.0)\n  end\nend","category":"page"},{"location":"basiccausal/","page":"Tutorial","title":"Tutorial","text":"Remember, in this style we have to use  ciid to convert a function into a RandVar","category":"page"},{"location":"basiccausal/","page":"Tutorial","title":"Tutorial","text":"outside_temp = ciid(outside_temp_, T=Float64)","category":"page"},{"location":"basiccausal/","page":"Tutorial","title":"Tutorial","text":"The inside_temp before considering the effects of the window is room temperature, unless the ac is on, which makes it colder.","category":"page"},{"location":"basiccausal/","page":"Tutorial","title":"Tutorial","text":"function inside_temp_(rng)\n  if Bool(is_ac_on(rng))\n    normal(rng, 20.0, 1.0)\n  else\n    normal(rng, 25.0, 1.0)\n  end\nend\n\ninside_temp = ciid(inside_temp_, T=Float64)","category":"page"},{"location":"basiccausal/","page":"Tutorial","title":"Tutorial","text":"47:Omega.normal(100.0, 1.0)::Float64","category":"page"},{"location":"basiccausal/","page":"Tutorial","title":"Tutorial","text":"Finally, the thermostat reading is inside_temp if the window is closed (we have perfect insulation), otherwise it's just the average of the outside and inside temperature","category":"page"},{"location":"basiccausal/","page":"Tutorial","title":"Tutorial","text":"function thermostat_(rng)\n  if Bool(is_window_open(rng))\n    (outside_temp(rng) + inside_temp(rng)) / 2.0\n  else\n    inside_temp(rng)\n  end\nend\n\nthermostat = ciid(thermostat_, T=Float64)","category":"page"},{"location":"basiccausal/","page":"Tutorial","title":"Tutorial","text":"Now with the model built, we can ask some questions:","category":"page"},{"location":"basiccausal/#Samples-from-the-prior","page":"Tutorial","title":"Samples from the prior","text":"","category":"section"},{"location":"basiccausal/","page":"Tutorial","title":"Tutorial","text":"The simplest task is to sample from the prior:","category":"page"},{"location":"basiccausal/","page":"Tutorial","title":"Tutorial","text":"julia> rand((timeofday, is_window_open, is_ac_on, outside_temp, inside_temp, thermostat), 5, alg = RejectionSample)\n5-element Array{Any,1}:\n (:afternoon, 0.0, 0.0, 32.349, 26.441, 26.441)   \n (:afternoon, 1.0, 0.0, 30.751, 25.143, 27.947)\n (:morning, 1.0, 0.0, 16.928, 24.146, 20.537)     \n (:afternoon, 1.0, 0.0, 30.521, 25.370, 27.946)\n (:morning, 1.0, 1.0, 16.495, 20.203, 18.349) ","category":"page"},{"location":"basiccausal/#Conditional-Inference","page":"Tutorial","title":"Conditional Inference","text":"","category":"section"},{"location":"basiccausal/","page":"Tutorial","title":"Tutorial","text":"You enter the room and the thermostat reads hot. what does this tell you about the variables?","category":"page"},{"location":"basiccausal/","page":"Tutorial","title":"Tutorial","text":"samples = rand((timeofday, iswindowopen, isacon, outsidetemp, insidetemp, thermostat),                 thermostat > 30.0, 5, alg = RejectionSample)","category":"page"},{"location":"basiccausal/","page":"Tutorial","title":"Tutorial","text":"\njulia> samples = rand((timeofday, is_window_open, is_ac_on, outside_temp, inside_temp, thermostat),\n                       thermostat > 30.0, 5, alg = RejectionSample)\n5-element Array{Any,1}:\n (:evening, 1.0, 0.0, 33.64609872046609, 26.822449458789542, 30.234274089627817) \n (:afternoon, 1.0, 0.0, 34.37763909867243, 26.16221853550574, 30.269928817089088)\n (:evening, 1.0, 0.0, 34.32198183192978, 26.6773921624331, 30.499686997181442)   \n (:afternoon, 1.0, 0.0, 34.05126597960254, 26.51833791813246, 30.2848019488675)  \n (:afternoon, 1.0, 0.0, 32.92982568498735, 27.56800059609554, 30.248913140541447)","category":"page"},{"location":"basiccausal/#Counter-Factual","page":"Tutorial","title":"Counter Factual","text":"","category":"section"},{"location":"basiccausal/","page":"Tutorial","title":"Tutorial","text":"If I were to close the window, and turn on the AC would that make it hotter or colder\"","category":"page"},{"location":"basiccausal/","page":"Tutorial","title":"Tutorial","text":"thermostatnew = replace(thermostat, is_ac_on => 1.0, is_window_open => 0.0)\ndiffsamples = rand(thermostatnew - thermostat, 10000, alg = RejectionSample)\njulia> mean(diffsamples)\n-4.246869797640215","category":"page"},{"location":"basiccausal/","page":"Tutorial","title":"Tutorial","text":"So in expectation, that intervention will make the thermostat colder.  But we can look more closely at the distribution:","category":"page"},{"location":"basiccausal/","page":"Tutorial","title":"Tutorial","text":"julia> UnicodePlots.histogram([diffsamples...])\n\n                 ┌────────────────────────────────────────┐ \n   (-11.0,-10.0] │ 37                                     │ \n    (-10.0,-9.0] │▇▇▇▇ 502                                │ \n     (-9.0,-8.0] │▇▇▇▇▇▇▇▇▇▇▇ 1269                        │ \n     (-8.0,-7.0] │▇▇▇▇▇ 581                               │ \n     (-7.0,-6.0] │▇▇▇▇ 497                                │ \n     (-6.0,-5.0] │▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇ 3926 │ \n     (-5.0,-4.0] │▇ 65                                    │ \n     (-4.0,-3.0] │ 5                                      │ \n     (-3.0,-2.0] │ 3                                      │ \n     (-2.0,-1.0] │▇ 97                                    │ \n      (-1.0,0.0] │▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇ 1960                  │ \n       (0.0,1.0] │▇▇▇▇ 494                                │ \n       (1.0,2.0] │▇▇ 197                                  │ \n       (2.0,3.0] │▇▇ 237                                  │ \n       (3.0,4.0] │▇ 118                                   │ \n       (4.0,5.0] │ 12                                     │ \n                 └────────────────────────────────────────┘ ","category":"page"},{"location":"basiccausal/","page":"Tutorial","title":"Tutorial","text":"In what scenarios would it still be hotter after turning on the AC and closing the window?","category":"page"},{"location":"basiccausal/","page":"Tutorial","title":"Tutorial","text":"rand((timeofday, outsidetemp, insidetemp, thermostat),       thermostatnew - thermostat > 0.0, 10, alg = RejectionSample)","category":"page"},{"location":"contrib/#Contribution","page":"Contribution Guide","title":"Contribution","text":"","category":"section"},{"location":"contrib/","page":"Contribution Guide","title":"Contribution Guide","text":"Omega makes a strict distrinction between the model and the inference algorithms. This makes it easy to add new inference algorithms to Omega.","category":"page"},{"location":"contrib/","page":"Contribution Guide","title":"Contribution Guide","text":"Here we will describe how to implement a very simple inference procedure: rejection sampling.","category":"page"},{"location":"contrib/","page":"Contribution Guide","title":"Contribution Guide","text":"The first step is to define a new abstract type that sub types Algorithm","category":"page"},{"location":"contrib/","page":"Contribution Guide","title":"Contribution Guide","text":"\"My Rejection Sampling\"\nabstract type MyRejectionSample <: Algorithm end","category":"page"},{"location":"contrib/","page":"Contribution Guide","title":"Contribution Guide","text":"Then add a method to Base.rand with the following type","category":"page"},{"location":"contrib/","page":"Contribution Guide","title":"Contribution Guide","text":"\"Sample from `x | y == true` with rejection sampling\"\nfunction Base.rand(ΩT::Type{OT}, y::RandVar, alg::Type{MyRejectionSample};\n                   n = 100,\n                   cb = default_cbs(n)) where {OT <: Ω}","category":"page"},{"location":"contrib/","page":"Contribution Guide","title":"Contribution Guide","text":"The first argument ΩT::Type{OT} is the type of Omega that will be passed through.\ny::RandVar is a random predicate that is being conditioned on\nalg::Type{MyRejectionSample} should be as written","category":"page"},{"location":"contrib/","page":"Contribution Guide","title":"Contribution Guide","text":"The remaining arguments are optional n is the number of samples, and cb are callbacks","category":"page"},{"location":"contrib/","page":"Contribution Guide","title":"Contribution Guide","text":"The implementation is then","category":"page"},{"location":"contrib/","page":"Contribution Guide","title":"Contribution Guide","text":"\"Sample from `x | y == true` with rejection sampling\"\nfunction Base.rand(ΩT::Type{OT}, y::RandVar, alg::Type{MyRejectionSample};\n                   n = 100,\n                   cb = default_cbs(n)) where {OT <: Ω}\n  # Run all callbacks\n  cb = runall(cb)\n\n  # Set of samples in Omega to return\n  samples = ΩT[]\n\n  # The number which have been accepted\n  accepted = 1\n  i = 1\n  while accepted < n\n    ω = ΩT()\n    if err(y(ω)) == 1.0\n      push!(samples, ω)\n      accepted += 1\n      cb(RunData(ω, accepted, 0.0, accepted), IterEnd)\n    else\n      cb(RunData(ω, accepted, 1.0, i), IterEnd)\n    end\n    i += 1\n  end\n  samples\nend","category":"page"},{"location":"inference/#Inference","page":"Conditional Inference","title":"Inference","text":"","category":"section"},{"location":"inference/","page":"Conditional Inference","title":"Conditional Inference","text":"note: Note\nTLDR: rand(x, y, n; alg = alg) draws n samples from x (any RandVar) conditioned on y (any RandVar whose elementype is Bool) and alg is the inference procedure. ```","category":"page"},{"location":"inference/","page":"Conditional Inference","title":"Conditional Inference","text":"The primary purpose of building a probabilistic model is to use it for inference. The kind of inference we shall describe is called posterior inference, Bayesian inference, conditional inference or simply probabilistic inference.","category":"page"},{"location":"inference/#Conditional-Sampling-Algorithms","page":"Conditional Inference","title":"Conditional Sampling Algorithms","text":"","category":"section"},{"location":"inference/","page":"Conditional Inference","title":"Conditional Inference","text":"While there are several kinds of thing you might like to know about a conditional distribution (such as its mode), currently, all inference algorithms perform conditional sampling only. To sample from a conditional distribution: pass two random variables to rand, the distribution you want to sample from, and the predicate you want to condition on. For example:","category":"page"},{"location":"inference/","page":"Conditional Inference","title":"Conditional Inference","text":"weight = β(2.0, 2.0)\nx = bernoulli(weight)\nrand(weight, x ==ᵣ 0; alg=RejectionSample)","category":"page"},{"location":"inference/","page":"Conditional Inference","title":"Conditional Inference","text":"It is fine to condition random variables on equalities or inequalities:","category":"page"},{"location":"inference/","page":"Conditional Inference","title":"Conditional Inference","text":"x1 = normal(0.0, 1.0)\nrand(x1, x1 > 0.0; alg=RejectionSample)","category":"page"},{"location":"inference/","page":"Conditional Inference","title":"Conditional Inference","text":"It's also fine to condition on functions of multiple variables","category":"page"},{"location":"inference/","page":"Conditional Inference","title":"Conditional Inference","text":"x1 = normal(0.0, 1.0)\nx2 = normal(0.0, 10)\nrand((x1, x2), x1 > x2; alg=RejectionSample)","category":"page"},{"location":"inference/","page":"Conditional Inference","title":"Conditional Inference","text":"Note: to sample from more than one random variable, just pass a tuple of RandVars to rand.","category":"page"},{"location":"inference/#Conditioning-with-cond","page":"Conditional Inference","title":"Conditioning with cond","text":"","category":"section"},{"location":"inference/","page":"Conditional Inference","title":"Conditional Inference","text":"rand(x, y) is simply a shorter way of saying rand(cond(x, y)). That is, the primary mechanism for inference in Omega is conditioning random variables using cond.","category":"page"},{"location":"inference/","page":"Conditional Inference","title":"Conditional Inference","text":"cond(::RandVar, ::RandVar)","category":"page"},{"location":"inference/#Conditioning-the-Prior","page":"Conditional Inference","title":"Conditioning the Prior","text":"","category":"section"},{"location":"inference/","page":"Conditional Inference","title":"Conditional Inference","text":"In Bayesian inference the term posterior distribution is often used instead of the conditional distribution.  Mathematically they are the same object, but posterior alludes to the fact that it is the distribution after (a posteriori) observing data. The distribution before observing data is often referred to as the prior.","category":"page"},{"location":"inference/","page":"Conditional Inference","title":"Conditional Inference","text":"However, conditioning is a more general concept than observing data, and we can meaningfully \"condition the prior\".","category":"page"},{"location":"inference/","page":"Conditional Inference","title":"Conditional Inference","text":"For example we can truncate a normal distribution through conditioning:","category":"page"},{"location":"inference/","page":"Conditional Inference","title":"Conditional Inference","text":"x = normal(0.0, 1.0)\nx_ = cond(x, x > 0.0)","category":"page"},{"location":"inference/","page":"Conditional Inference","title":"Conditional Inference","text":"A shorter way to write this is to pass a unary function as the second argument to cond","category":"page"},{"location":"inference/","page":"Conditional Inference","title":"Conditional Inference","text":"x = cond(normal(0.0, 1.0), rv -> rv > 0.0)","category":"page"},{"location":"inference/","page":"Conditional Inference","title":"Conditional Inference","text":"Or suppose we want a poisson distribution over the even numbers","category":"page"},{"location":"inference/","page":"Conditional Inference","title":"Conditional Inference","text":"julia> x = cond(poisson(3.0), iseven)\njulia> rand(x, 5; alg = RejectionSample)\n5-element Array{Int64,1}:\n 2\n 6\n 2\n 4\n 0","category":"page"},{"location":"inference/#Conditions-Propagate","page":"Conditional Inference","title":"Conditions Propagate","text":"","category":"section"},{"location":"inference/","page":"Conditional Inference","title":"Conditional Inference","text":"When you compose conditoned random variables together, their conditions propagate.  That is, if θ is conditioned, and x depends on θ, then x inherits all the conditions of θ automatically.  For example:","category":"page"},{"location":"inference/","page":"Conditional Inference","title":"Conditional Inference","text":"ispos(x) = x > 0.0\nweight = cond(normal(72, 1.0), ispos)\nheight = cond(normal(1.78, 1.0), ispos)\nbmi = weight ./ height","category":"page"},{"location":"inference/","page":"Conditional Inference","title":"Conditional Inference","text":"bmi is a function of both weight and height, both of which have their own conditions (namely, they are positive). Omega automatically propagates the conditions from weight and height onto bmi.","category":"page"},{"location":"randvar/","page":"RandVar","title":"RandVar","text":"Random Variables","category":"page"},{"location":"performance/#Performance-Tips","page":"Performance Tips","title":"Performance Tips","text":"","category":"section"},{"location":"performance/#Check-that-the-type-of-random-variables-are-inferred.","page":"Performance Tips","title":"Check that the type of random variables are inferred.","text":"","category":"section"},{"location":"performance/","page":"Performance Tips","title":"Performance Tips","text":"By default, a random variable will print the inferred return type. If this type is broader than you expect, you may be losing type information.","category":"page"},{"location":"performance/","page":"Performance Tips","title":"Performance Tips","text":"julia> x = normal(0, 1)\n3:Normal(0, 1)::Float64\n\njulia> ~ ω -> bernoulli(ω, 0.5, Bool) ?  poisson(ω, 0.3) : uniform(ω, 0.0, 1.0)\n15:getfield(Main, Symbol(\"##19#20\"))()()::Union{Float64, Int64}","category":"page"},{"location":"performance/#Use-const","page":"Performance Tips","title":"Use const","text":"","category":"section"},{"location":"performance/","page":"Performance Tips","title":"Performance Tips","text":"It's common in Omega models to have globally defined random variables be parents of other variables. If const is not used, this can lead to type instability. For example:","category":"page"},{"location":"performance/","page":"Performance Tips","title":"Performance Tips","text":"x = normal(0, 1)\n16:Normal(0, 1)::Float64\n\ny_(ω) = 3.0 + x(ω)\n\ny = ~y_\n17:y_()::Any","category":"page"},{"location":"performance/","page":"Performance Tips","title":"Performance Tips","text":"Observe that y_ has Any as the return type","category":"page"},{"location":"performance/","page":"Performance Tips","title":"Performance Tips","text":"x = normal(0, 1)\n\ny_(ω) = 3.0 + x(ω)\n\ny = ~y_\n4:y_()::Float64","category":"page"},{"location":"omega/#Omega","page":"Ω","title":"Omega","text":"","category":"section"},{"location":"omega/","page":"Ω","title":"Ω","text":"As described in [models], random variables are thin wrappers around functions which take as input a value ω::Ω We previously described Ω as a type of AbstractRNG.  This is true, but the full store is a bit more complex","category":"page"},{"location":"omega/#Ω","page":"Ω","title":"Ω","text":"","category":"section"},{"location":"omega/","page":"Ω","title":"Ω","text":"Ω is an abstract type which represents a sample space in probability theory.","category":"page"},{"location":"omega/","page":"Ω","title":"Ω","text":"Ω","category":"page"},{"location":"omega/","page":"Ω","title":"Ω","text":"SimpleΩ","category":"page"},{"location":"omega/#Samplers-vs-Random-Variables","page":"Ω","title":"Samplers vs Random Variables","text":"","category":"section"},{"location":"omega/","page":"Ω","title":"Ω","text":"A sampler and a random variable have many similarities but are different. To demonstrate the difference, we shall show the changes one has to make to turn a sampler into an Omega RandVar.","category":"page"},{"location":"omega/","page":"Ω","title":"Ω","text":"Create a sampler that ","category":"page"},{"location":"omega/","page":"Ω","title":"Ω","text":"x1() = rand() > 0.5","category":"page"},{"location":"omega/","page":"Ω","title":"Ω","text":"x1 uses Random.GLOBAL_RNG in the background.  Instead, make it explicit:","category":"page"},{"location":"omega/","page":"Ω","title":"Ω","text":"julia> x2(rng::AbstractRNG) = rand(rng) > 0.5\njulia> x2(Random.MersenneTwister())\nfalse","category":"page"},{"location":"omega/","page":"Ω","title":"Ω","text":"Make a cosmetic change","category":"page"},{"location":"omega/","page":"Ω","title":"Ω","text":"julia> x2(rng::AbstractRNG) = rand(rng) > 0.5\njulia> x2(Random.MersenneTwister())\nfalse","category":"page"},{"location":"causal/#Causal-Inference","page":"Causal Inference","title":"Causal Inference","text":"","category":"section"},{"location":"causal/","page":"Causal Inference","title":"Causal Inference","text":"Omega supports causal inference through the replace function.  Causal inference is a topic of much confusion, we recommend this blog post for a primer.","category":"page"},{"location":"causal/#Causal-Intervention-the-replace-operator","page":"Causal Inference","title":"Causal Intervention - the replace operator","text":"","category":"section"},{"location":"causal/","page":"Causal Inference","title":"Causal Inference","text":"The replace operator models an intervention to a model. It changes the model.","category":"page"},{"location":"causal/","page":"Causal Inference","title":"Causal Inference","text":"Omega.replace","category":"page"},{"location":"causal/","page":"Causal Inference","title":"Causal Inference","text":"In Omega we use the syntax:","category":"page"},{"location":"causal/","page":"Causal Inference","title":"Causal Inference","text":"replace(X, θold => θnew)","category":"page"},{"location":"causal/","page":"Causal Inference","title":"Causal Inference","text":"To mean the random variable X where θold has been replaced with θnew.  For this to be meaningful, θold must be a parent of x.","category":"page"},{"location":"causal/","page":"Causal Inference","title":"Causal Inference","text":"Let's look at an example:","category":"page"},{"location":"causal/","page":"Causal Inference","title":"Causal Inference","text":"julia> μold = normal(0.0, 1.0)\n45:Omega.normal(0.0, 1.0)::Float64\n\njulia> x = normal(μold, 1.0)\n46:Omega.normal(Omega.normal, 1.0)::Float64\n\njulia> μnew = 100.0\n47:Omega.normal(100.0, 1.0)::Float64\n\njulia> xnew = replace(x, μold => μnew)\njulia> rand((x, xnew))\n(-2.664230595692529, 96.99998702926271)","category":"page"},{"location":"causal/","page":"Causal Inference","title":"Causal Inference","text":"Observe that the sample from xnew is much greater, because it has the mean of the normal distribution has been changed to 100","category":"page"},{"location":"causal/#Replace-a-Random-Variable-with-a-Random-Variable","page":"Causal Inference","title":"Replace a Random Variable with a Random Variable","text":"","category":"section"},{"location":"causal/","page":"Causal Inference","title":"Causal Inference","text":"Repacing a random variable with a constant is actually a special case of replacing a random variable with another random variable.  The syntax is the same:","category":"page"},{"location":"causal/","page":"Causal Inference","title":"Causal Inference","text":"julia> xnewnew = replace(x, μold => normal(200.0, 1.0))\njulia> rand((x, xnew, xnewnew))\n(-1.2756627673001866, 99.1080578175426, 198.14711316585564)","category":"page"},{"location":"causal/#Changing-Multiple-Variables","page":"Causal Inference","title":"Changing Multiple Variables","text":"","category":"section"},{"location":"causal/","page":"Causal Inference","title":"Causal Inference","text":"replace allow you to change many variables at once  Simply pass in a variable number of pairs, or a dictionary:","category":"page"},{"location":"causal/","page":"Causal Inference","title":"Causal Inference","text":"μ1 = normal(0, 1)\nμ2 = normal(0, 1)\ny = normal(μ1 + μ2, 1)\nxnewmulti = replace(y, μ1 => normal(200.0, 1.0), μ2 => normal(300.0, 1.0))\nrand((xnewmulti))\n(-1.2756627673001866, 99.1080578175426, 198.14711316585564)","category":"page"},{"location":"causal/#Counterfactuals","page":"Causal Inference","title":"Counterfactuals","text":"","category":"section"},{"location":"causal/","page":"Causal Inference","title":"Causal Inference","text":"The utility of replace may not be obvious at first glance. We can use replace and cond separately and in combination to ask lots of different kinds of questions. In this example, we model the relationship betwee the weather outside and teh thermostat reading inside a house. Broadly, the model says that the weather outside is dictataed by the time of day, while the temperature inside is determined by whether the air conditioning is on, and whether the window is open.","category":"page"},{"location":"causal/","page":"Causal Inference","title":"Causal Inference","text":"First, setup simple priors over the time of day, and variables to determine whether the air conditioning is on and whether the iwndow is open:","category":"page"},{"location":"causal/","page":"Causal Inference","title":"Causal Inference","text":"timeofday = uniform([:morning, :afternoon, :evening])\nis_window_open = bernoulli(0.5,Bool)\nis_ac_on = bernoulli(0.3,Bool)","category":"page"},{"location":"causal/","page":"Causal Inference","title":"Causal Inference","text":"Second, assume that the outside temperature depends on the time of day, being hottest in the afternoon, but cold at night:","category":"page"},{"location":"causal/","page":"Causal Inference","title":"Causal Inference","text":"function outside_temp_(rng)\n  if timeofday(rng) == :morning\n    normal(rng, 20.0, 1.0)\n  elseif timeofday(rng) == :afternoon\n    normal(rng, 32.0, 1.0)\n  else\n    normal(rng, 10.0, 1.0)\n  end\nend","category":"page"},{"location":"causal/","page":"Causal Inference","title":"Causal Inference","text":"Remember, in this style we have to use  ciid to convert a function into a RandVar","category":"page"},{"location":"causal/","page":"Causal Inference","title":"Causal Inference","text":"outside_temp = ciid(outside_temp_)","category":"page"},{"location":"causal/","page":"Causal Inference","title":"Causal Inference","text":"The inside_temp before considering the effects of the window is room temperature, unless the ac is on, which makes it colder.","category":"page"},{"location":"causal/","page":"Causal Inference","title":"Causal Inference","text":"function inside_temp_(rng)\n  if is_ac_on(rng)\n    normal(rng, 20.0, 1.0)\n  else\n    normal(rng, 25.0, 1.0)\n  end\nend\n\ninside_temp = ciid(inside_temp_, T=Float64)","category":"page"},{"location":"causal/","page":"Causal Inference","title":"Causal Inference","text":"Finally, the thermostat reading is inside_temp if the window is closed (we have perfect insulation), otherwise it's just the average of the outside and inside temperature","category":"page"},{"location":"causal/","page":"Causal Inference","title":"Causal Inference","text":"function thermostat_(rng)\n  if is_window_open(rng)\n    (outside_temp(rng) + inside_temp(rng)) / 2.0\n  else\n    inside_temp(rng)\n  end\nend\n\nthermostat = ciid(thermostat_, T=Float64)","category":"page"},{"location":"causal/","page":"Causal Inference","title":"Causal Inference","text":"Now with the model built, we can ask some questions:","category":"page"},{"location":"causal/#Samples-from-the-prior","page":"Causal Inference","title":"Samples from the prior","text":"","category":"section"},{"location":"causal/","page":"Causal Inference","title":"Causal Inference","text":"The simplest task is to sample from the prior:","category":"page"},{"location":"causal/","page":"Causal Inference","title":"Causal Inference","text":"julia> rand((timeofday, is_window_open, is_ac_on, outside_temp, inside_temp, thermostat), 5, alg = RejectionSample)\n5-element Array{Tuple{Symbol,Bool,Bool,Float64,Float64,Float64},1}:\n (:evening, true, false, 10.310689624432637, 26.144122188682584, 18.22740590655761)\n (:afternoon, false, false, 32.30806450465544, 22.861739827796345, 22.861739827796345)\n (:morning, false, false, 20.161172183596964, 25.128141190979573, 25.128141190979573)\n (:evening, true, false, 10.239806337680982, 26.81486040128365, 18.527333369482314)\n (:morning, true, false, 20.56559745560037, 27.380632072360157, 23.973114763980263)","category":"page"},{"location":"causal/#Conditional-Inference","page":"Causal Inference","title":"Conditional Inference","text":"","category":"section"},{"location":"causal/","page":"Causal Inference","title":"Causal Inference","text":"You enter the room and the thermostat reads hot. what does this tell you about the variables?","category":"page"},{"location":"causal/","page":"Causal Inference","title":"Causal Inference","text":"\njulia> samples = rand((timeofday, is_window_open, is_ac_on, outside_temp, inside_temp, thermostat),\n                       thermostat > 30.0, 5, alg = RejectionSample)\n5-element Array{Tuple{Symbol,Bool,Bool,Float64,Float64,Float64},1}:\n (:afternoon, true, false, 32.66172359406305, 28.459719413318684, 30.560721503690864)\n (:afternoon, true, false, 33.411018400286764, 26.638821969105173, 30.02492018469597)\n (:afternoon, true, false, 32.92666992107552, 27.87634864444088, 30.4015092827582)\n (:afternoon, true, false, 34.941029761615916, 25.66825864439438, 30.304644203005147)\n (:afternoon, true, false, 33.82296040117437, 26.237305008998273, 30.030132705086324)","category":"page"},{"location":"causal/#Counter-Factual","page":"Causal Inference","title":"Counter Factual","text":"","category":"section"},{"location":"causal/","page":"Causal Inference","title":"Causal Inference","text":"If I were to close the window, and turn on the AC would that make it hotter or colder\"","category":"page"},{"location":"causal/","page":"Causal Inference","title":"Causal Inference","text":"thermostatnew = replace(thermostat, is_ac_on => true, is_window_open => false)\ndiffsamples = rand(thermostatnew - thermostat, 10000, alg = RejectionSample)\njulia> mean(diffsamples)\n-4.246869797640215","category":"page"},{"location":"causal/","page":"Causal Inference","title":"Causal Inference","text":"So in expectation, that intervention will make the thermostat colder.  But we can look more closely at the distribution:","category":"page"},{"location":"causal/","page":"Causal Inference","title":"Causal Inference","text":"julia> UnicodePlots.histogram(diffsamples)\n\n                 ┌────────────────────────────────────────┐ \n   (-11.0,-10.0] │ 37                                     │ \n    (-10.0,-9.0] │▇▇▇▇ 502                                │ \n     (-9.0,-8.0] │▇▇▇▇▇▇▇▇▇▇▇ 1269                        │ \n     (-8.0,-7.0] │▇▇▇▇▇ 581                               │ \n     (-7.0,-6.0] │▇▇▇▇ 497                                │ \n     (-6.0,-5.0] │▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇ 3926 │ \n     (-5.0,-4.0] │▇ 65                                    │ \n     (-4.0,-3.0] │ 5                                      │ \n     (-3.0,-2.0] │ 3                                      │ \n     (-2.0,-1.0] │▇ 97                                    │ \n      (-1.0,0.0] │▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇ 1960                  │ \n       (0.0,1.0] │▇▇▇▇ 494                                │ \n       (1.0,2.0] │▇▇ 197                                  │ \n       (2.0,3.0] │▇▇ 237                                  │ \n       (3.0,4.0] │▇ 118                                   │ \n       (4.0,5.0] │ 12                                     │ \n                 └────────────────────────────────────────┘ ","category":"page"},{"location":"causal/","page":"Causal Inference","title":"Causal Inference","text":"In what scenarios would it still be hotter after turning on the AC and closing the window?","category":"page"},{"location":"causal/","page":"Causal Inference","title":"Causal Inference","text":"julia> rand((timeofday, outside_temp, inside_temp, thermostat), thermostatnew - thermostat > 0.0, 5, alg = RejectionSample)\n5-element Array{Tuple{Symbol,Float64,Float64,Float64},1}:\n (:evening, 8.99858009405822, 26.42261048649467, 17.710595290276444)\n (:evening, 11.016416633842283, 24.852317088939945, 17.934366861391112)\n (:evening, 9.744613418296744, 25.556084959799456, 17.6503491890481)\n (:evening, 9.381925134669295, 25.6283276833937, 17.505126409031497)\n (:evening, 9.121300508670375, 25.182478479511474, 17.151889494090923)","category":"page"},{"location":"internalsoverview/#Overview","page":"Overview","title":"Overview","text":"","category":"section"},{"location":"internalsoverview/","page":"Overview","title":"Overview","text":"The desiderata for Omega are to increase the expressiveness of probabilistic programming, with minimal sacrifices to performance.","category":"page"},{"location":"internalsoverview/","page":"Overview","title":"Overview","text":"Support conditioning on arbitrary predicates\nSupport conditioning on distributional propereties\nSupport causal inference\nBe based on solid probabilistic foundations (i.e., measure theory)\nIntegrate seamlessly with Julia\nBe fast","category":"page"},{"location":"internalsoverview/","page":"Overview","title":"Overview","text":"Some of these points are contradictory.  For example only pure functions exist in measure theory, whereas julia programs may have side effects. Also there are tradeoffs between being as fast as possible, while being as general as possible.","category":"page"},{"location":"internalsoverview/","page":"Overview","title":"Overview","text":"We think we have found a good compromise in Julia.","category":"page"},{"location":"internalsoverview/#MiniOmega","page":"Overview","title":"MiniOmega","text":"","category":"section"},{"location":"internalsoverview/","page":"Overview","title":"Overview","text":"Omega is structured around two primary abstract types Ω and RandVar.","category":"page"},{"location":"internalsoverview/","page":"Overview","title":"Overview","text":"module MiniOmega\nusing Random\n\nmutable struct Ω <: Random.AbstractRNG\n  data::Dict{Int, Any}\n  i::Int\nend\n\nΩ() = Ω(Dict(), 0)\n\nfunction Base.rand(w::Ω, args...)\n  w.i += 1\n  get!(w.data, w.i, rand(Random.GLOBAL_RNG, args...))\nend\n\nBase.rand(w::Ω, args...) = (w.i += 1; get!(w.data, w.i, rand(args...)))\nBase.rand(w::Ω, dims::Vararg{Integer,N} where N) = (w.i += 1; get!(w.data, w.i, rand(dims)))\n\nstruct RandVar\n  f::Function\nend\n\n(rv::RandVar)(w::Ω) = (w.i = 0; rv.f(w))\n\nBase.rand(x::RandVar) = x(Ω())\n\ncond(x::RandVar, y::RandVar) = RandVar(rng -> y(rng) ? x(rng) : error())\n\n\"Rejetion Sampling\"\nBase.rand(x::RandVar) = try x(Ω()) catch; rand(x) end\n\nexport RandVar, Ω\nend","category":"page"},{"location":"internalsoverview/","page":"Overview","title":"Overview","text":"## Example\nusing Main.MiniOmega\nx_(rng) = rand(rng)\nx = RandVar(x_)\nω = Ω()\nx(ω)","category":"page"},{"location":"higher/#Distributional-Inference","page":"Distributional Inference","title":"Distributional Inference","text":"","category":"section"},{"location":"higher/","page":"Distributional Inference","title":"Distributional Inference","text":"note: Note\nTLDR: Omega allows you to turn a distributional property (e.g. mean, var, kurtosis), from a concrete value (e.g. a Float64) into a RandVar.  These RandVars can then be conditioned.Use either rcd, rcdₛ or rid.rcd\nrid\nrcdₛrid are rcd are equivlaet in some cases. rid is much more efficient, so use that if possible. If they are not equivlanet and you must use rcd, it's likely you will want to use the rcdₛ which uses soft equality [ref]","category":"page"},{"location":"higher/","page":"Distributional Inference","title":"Distributional Inference","text":"Since this is a new concept, it requires some explanation.","category":"page"},{"location":"higher/#Random-Distributional-Properties","page":"Distributional Inference","title":"Random Distributional Properties","text":"","category":"section"},{"location":"higher/","page":"Distributional Inference","title":"Distributional Inference","text":"Distributional properties are fixed (often real) values, but in a sense they are random variables too. For example, rainfall depends on temperature, the season, the presence of clouds, and so on. With respect to a model, expected rainfall is a real value, but it changes if we obtain new information. For example it rises if we observe clouds and falls to zero if we observe their absence. These two expectations becomes a random variable over expectations – a conditional expectation – when we take into account the probabilities of the presence or absence of clouds. Moreover, for each random variable in the model there is a corresponding conditional expectation. For instance, with respect to the season, conditional expected rainfall is a random variable over four expectations, one for each season; with respect to temperature it is a continuous distribution. These conditional expectations capture the uncertainty over expected rainfall that results from other variables in the model, whereas the unconditional expected rainfall averages all the uncertainty away.","category":"page"},{"location":"higher/","page":"Distributional Inference","title":"Distributional Inference","text":"Omega has a number of mechanisms to automatically capture the uncertainty over any distributional property.  It is based on a new concept called the random conditional distribution.","category":"page"},{"location":"higher/#Random-Conditional-Distribution","page":"Distributional Inference","title":"Random Conditional Distribution","text":"","category":"section"},{"location":"higher/","page":"Distributional Inference","title":"Distributional Inference","text":"rcd","category":"page"},{"location":"higher/#Random-Interventional-Distribution","page":"Distributional Inference","title":"Random Interventional Distribution","text":"","category":"section"},{"location":"higher/","page":"Distributional Inference","title":"Distributional Inference","text":"rid","category":"page"},{"location":"higher/#rcd-or-rid?","page":"Distributional Inference","title":"rcd or rid?","text":"","category":"section"},{"location":"higher/","page":"Distributional Inference","title":"Distributional Inference","text":"In many cases rcd and rid are equivalent.  In these cases you should prefer rid, since it is much more efficient.  The conditions with which they are equivalent are a bit subtle.","category":"page"},{"location":"faq/#FAQ","page":"FAQ","title":"FAQ","text":"","category":"section"},{"location":"faq/","page":"FAQ","title":"FAQ","text":"How to sample from a joint distribution (more than one random variable at a time)?","category":"page"},{"location":"faq/","page":"FAQ","title":"FAQ","text":"Pass a tuple of random variables, e.g: rand((x, y, z)).  This is not the same as sampling from one variable at a time – e.g. x_ = rand(x); y_ = rand(y), since these samples have lost dependency information.","category":"page"},{"location":"faq/","page":"FAQ","title":"FAQ","text":"How do I apply a transformation f to a random variable ","category":"page"},{"location":"faq/","page":"FAQ","title":"FAQ","text":"Some are already defined, e.g. sqrt(uniform(0, 1)), for everything else use lift, e.g. lift(f(x))","category":"page"},{"location":"faq/","page":"FAQ","title":"FAQ","text":"What's the difference between Omega and Probabilistic Programming Language X","category":"page"},{"location":"faq/","page":"FAQ","title":"FAQ","text":"In contrast to most PPLs,  Omega takes both random variables and the sample space objects to be first class probabilistic constructs.  This makes it easier to implement conditioning on predicates, causal inference and higher-order inference.  See also: Omega vs Other PPLS. ","category":"page"},{"location":"miniomega/","page":"-","title":"-","text":"The following code is a minimal implementation of Omega.","category":"page"},{"location":"miniomega/","page":"-","title":"-","text":"module MiniOmega\nusing Random\n\nmutable struct Ω <: Random.AbstractRNG\n  data::Dict{Int, Any}\n  i::Int\nend\n\nΩ() = Ω(Dict(), 0)\n\nfunction Base.rand(w::Ω, args...)\n  w.i += 1\n  get!(w.data, w.i, rand(Random.GLOBAL_RNG, args...))\nend\n\nBase.rand(w::Ω, args...) = (w.i += 1; get!(w.data, w.i, rand(args...)))\nBase.rand(w::Ω, dims::Vararg{Integer,N} where N) = (w.i += 1; get!(w.data, w.i, rand(dims)))\n\nstruct RandVar\n  f::Function\nend\n\n(rv::RandVar)(w::Ω) = (w.i = 0; rv.f(w))\n\nBase.rand(x::RandVar) = x(Ω())\n\ncond(x::RandVar, y::RandVar) = RandVar(rng -> y(rng) ? x(rng) : error())\n\n\"Rejetion Sampling\"\nBase.rand(x::RandVar) = try x(Ω()) catch; rand(x) end\n\nexport RandVar, Ω\nend","category":"page"},{"location":"miniomega/","page":"-","title":"-","text":"## Example\nusing Main.MiniOmega\nx_(rng) = rand(rng)\nx = RandVar(x_)\nω = Ω()\nx(ω)","category":"page"},{"location":"basictutorial/#Basic-Tutorial","page":"Basic Tutorial","title":"Basic Tutorial","text":"","category":"section"},{"location":"basictutorial/","page":"Basic Tutorial","title":"Basic Tutorial","text":"In this tutorial we will run through the basics of creating a model and conditioning it.","category":"page"},{"location":"basictutorial/","page":"Basic Tutorial","title":"Basic Tutorial","text":"First load Omega:","category":"page"},{"location":"basictutorial/","page":"Basic Tutorial","title":"Basic Tutorial","text":"using Omega, Distributions","category":"page"},{"location":"basictutorial/","page":"Basic Tutorial","title":"Basic Tutorial","text":"If you tossed a coin and observed the sequqnce HHHHH, you would be a little suspicious, HHHHHHHH would make you very suspicious. Elementary probability theory tells us that for a fair coin, HHHHHHHH is just a likely outcome as HHTTHHTH.  What gives? We will use Omega to model this behaviour, and see how that belief about a coin changes after observing a number of tosses.","category":"page"},{"location":"basictutorial/","page":"Basic Tutorial","title":"Basic Tutorial","text":"Model the coin as a bernoulli distribution.  The weight of a bernoulli determines the probability it comes up true (which represents heads). Use a beta distribution to represent our prior belief weight of the coin.","category":"page"},{"location":"basictutorial/","page":"Basic Tutorial","title":"Basic Tutorial","text":"weight = @~ Beta(2.0, 2.0)","category":"page"},{"location":"basictutorial/","page":"Basic Tutorial","title":"Basic Tutorial","text":"A beta distribution is appropriate here because it is bounded between 0 and 1. ","category":"page"},{"location":"basictutorial/","page":"Basic Tutorial","title":"Basic Tutorial","text":"Draw a 10000 samples from weight using rand:","category":"page"},{"location":"basictutorial/","page":"Basic Tutorial","title":"Basic Tutorial","text":"beta_samples = randsample(weight, 10000)","category":"page"},{"location":"basictutorial/","page":"Basic Tutorial","title":"Basic Tutorial","text":"Let's see what this distribution looks like using UnicodePlots.  If you don't have it installed already install with:","category":"page"},{"location":"basictutorial/","page":"Basic Tutorial","title":"Basic Tutorial","text":"] add UnicodePlots","category":"page"},{"location":"basictutorial/","page":"Basic Tutorial","title":"Basic Tutorial","text":"To visualize the distribution, plot a histogram of the samples:","category":"page"},{"location":"basictutorial/","page":"Basic Tutorial","title":"Basic Tutorial","text":"using UnicodePlots\nUnicodePlots.histogram(beta_samples)","category":"page"},{"location":"basictutorial/","page":"Basic Tutorial","title":"Basic Tutorial","text":"             ┌────────────────────────────────────────┐ \n   (0.0,0.1] │▇▇▇▇▇▇ 279                              │ \n   (0.1,0.2] │▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇ 727                   │ \n   (0.2,0.3] │▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇ 1218       │ \n   (0.3,0.4] │▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇ 1354    │ \n   (0.4,0.5] │▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇ 1482 │ \n   (0.5,0.6] │▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇ 1426  │ \n   (0.6,0.7] │▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇ 1406   │ \n   (0.7,0.8] │▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇ 1124         │ \n   (0.8,0.9] │▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇ 702                    │ \n   (0.9,1.0] │▇▇▇▇▇▇ 282                              │ \n             └────────────────────────────────────────┘","category":"page"},{"location":"basictutorial/","page":"Basic Tutorial","title":"Basic Tutorial","text":"The distribution is symmetric around 0.5 and has support over the the interval [0, 1].","category":"page"},{"location":"basictutorial/","page":"Basic Tutorial","title":"Basic Tutorial","text":"So far we have not done anything we couldn't do with Distributions.jl. A primary distinction between a package like Distribution.jl, is that Omega.jl allows you to condition probability distributions.","category":"page"},{"location":"basictutorial/","page":"Basic Tutorial","title":"Basic Tutorial","text":"Create a model representing four flips of the coin. Since a coin can be heads or tales, the appropriate distribution is the bernouli distribution:","category":"page"},{"location":"basictutorial/","page":"Basic Tutorial","title":"Basic Tutorial","text":"nflips = 4\ncoinflips_ = [Bernoulli.(weight, Bool) for i = 1:nflips]","category":"page"},{"location":"basictutorial/","page":"Basic Tutorial","title":"Basic Tutorial","text":"Take note that weight is the random variable defined previously. bernoulli takes a type as its secoond argument; Bool indicates the result will be a Bool rather than an Int.","category":"page"},{"location":"basictutorial/","page":"Basic Tutorial","title":"Basic Tutorial","text":"coinflips is a normal Julia array of Random Variables (RandVars). For reasons we will elaborate in later sections, it will be useful to have an Array-valued RandVar (instead of an Array of RandVar).","category":"page"},{"location":"basictutorial/","page":"Basic Tutorial","title":"Basic Tutorial","text":"One way to do this (there are several ways discuseed later), is to use the function randarray","category":"page"},{"location":"basictutorial/","page":"Basic Tutorial","title":"Basic Tutorial","text":"coinflips = randarray(coinflips_)","category":"page"},{"location":"basictutorial/","page":"Basic Tutorial","title":"Basic Tutorial","text":"coinflips is a RandVar and hence we can sample from it with rand","category":"page"},{"location":"basictutorial/","page":"Basic Tutorial","title":"Basic Tutorial","text":"julia> rand(coinflips)\n4-element Array{Bool,1}:\n  true\n false\n false\n false","category":"page"},{"location":"basictutorial/","page":"Basic Tutorial","title":"Basic Tutorial","text":"Now we can condition the model. We want to find the conditional distribution over the weight of the coin given some observations.","category":"page"},{"location":"basictutorial/","page":"Basic Tutorial","title":"Basic Tutorial","text":"First create some fake data","category":"page"},{"location":"basictutorial/","page":"Basic Tutorial","title":"Basic Tutorial","text":"observations = [true, true, true, false]","category":"page"},{"location":"basictutorial/","page":"Basic Tutorial","title":"Basic Tutorial","text":"Create a predicate that tests whether simulating from the model matches the observed data:","category":"page"},{"location":"basictutorial/","page":"Basic Tutorial","title":"Basic Tutorial","text":"condition = coinflips ==ᵣ observations","category":"page"},{"location":"basictutorial/","page":"Basic Tutorial","title":"Basic Tutorial","text":"condition is a random variable; we can sample from it.  The function ==ᵣ (and more generally functions subscripted with ᵣ) should be read as \"a realization of coinflips == observations\"","category":"page"},{"location":"basictutorial/","page":"Basic Tutorial","title":"Basic Tutorial","text":"We can use rand to sample from the model conditioned on condition being true:","category":"page"},{"location":"basictutorial/","page":"Basic Tutorial","title":"Basic Tutorial","text":"weight_samples = rand(weight, condition, 1000; alg = RejectionSample)","category":"page"},{"location":"basictutorial/","page":"Basic Tutorial","title":"Basic Tutorial","text":"weight_samples is a set of 1000 samples from the conditional (sometimes called posterior) distribution of weight condition on the fact that coinflips == observations.","category":"page"},{"location":"basictutorial/","page":"Basic Tutorial","title":"Basic Tutorial","text":"In this case, rand takes","category":"page"},{"location":"basictutorial/","page":"Basic Tutorial","title":"Basic Tutorial","text":"A random variable we want to sample from\nA predicate (type RandVar which evaluates to a Bool) that we want to condition on, i.e. assert that it is true\nAn inference algorithm.  Here we use rejection sampling.","category":"page"},{"location":"basictutorial/","page":"Basic Tutorial","title":"Basic Tutorial","text":"Plot a histogram of the weights like before:","category":"page"},{"location":"basictutorial/","page":"Basic Tutorial","title":"Basic Tutorial","text":"julia> UnicodePlots.histogram(weight_samples)\n             ┌────────────────────────────────────────┐ \n   (0.1,0.2] │▇ 4                                     │ \n   (0.2,0.3] │▇▇▇ 22                                  │ \n   (0.3,0.4] │▇▇▇▇▇▇▇▇▇▇▇ 69                          │ \n   (0.4,0.5] │▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇ 147             │ \n   (0.5,0.6] │▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇ 185       │ \n   (0.6,0.7] │▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇ 226 │ \n   (0.7,0.8] │▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇ 203     │ \n   (0.8,0.9] │▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇ 120                 │ \n   (0.9,1.0] │▇▇▇▇ 23                                 │ \n             └────────────────────────────────────────┘ \n","category":"page"},{"location":"basictutorial/","page":"Basic Tutorial","title":"Basic Tutorial","text":"Observe that our belief about the weight has now changed. We are more convinced the coin is biased towards heads (true).","category":"page"},{"location":"model/","page":"Modeling","title":"Modeling","text":"In Omega, the main thing one does is construct random variables, and then compute inferences from them.  ","category":"page"},{"location":"model/","page":"Modeling","title":"Modeling","text":"Omega comes with a small number of built-in primitive distributions.  One example  is the standard uniform:","category":"page"},{"location":"model/","page":"Modeling","title":"Modeling","text":"using Omega\nx1 = 1 ~ StdUniform{Float64}()","category":"page"},{"location":"model/","page":"Modeling","title":"Modeling","text":"What is the 1 doing here?  To explain, we need to introduce the idea of a random variable class.  Intuitively, a random variable class is a collection of random variables.","category":"page"},{"location":"model/","page":"Modeling","title":"Modeling","text":"Tec","category":"page"},{"location":"model/","page":"Modeling","title":"Modeling","text":"using Omega\nx1 = 1 ~ StdUniform{Float64}()","category":"page"},{"location":"model/","page":"Modeling","title":"Modeling","text":"using  Distributions\nx1 = @~ Uniform(0.0, 1.0)","category":"page"},{"location":"model/","page":"Modeling","title":"Modeling","text":"x1 is a random variable not a sample. To construct another random variable x2, we do the same. ","category":"page"},{"location":"model/","page":"Modeling","title":"Modeling","text":"x2 = Uniform(0.0, 1.0)","category":"page"},{"location":"model/","page":"Modeling","title":"Modeling","text":"x1 and x2 are identically distributed and independent (i.i.d.).","category":"page"},{"location":"model/","page":"Modeling","title":"Modeling","text":"julia> randsample((x1, x2))\n(0.5602978842341093, 0.9274576159629635)","category":"page"},{"location":"model/","page":"Modeling","title":"Modeling","text":"Contrast this with:","category":"page"},{"location":"model/","page":"Modeling","title":"Modeling","text":"julia> randsample((x1, x1))\n(0.057271529749001626, 0.057271529749001626)","category":"page"},{"location":"model/#Composition","page":"Modeling","title":"Composition","text":"","category":"section"},{"location":"model/","page":"Modeling","title":"Modeling","text":"There are two ways to compose random variables: the statistical style, which can be less verbose, and more intuitive, but has some limitations, and the explicit style, which is more general.","category":"page"},{"location":"model/","page":"Modeling","title":"Modeling","text":"In the statistical style we create random variables by combining a number of primitives.","category":"page"},{"location":"model/","page":"Modeling","title":"Modeling","text":"Statistical style is convenient because it allows us to treat a random variable which returns values of type T as if it is a value of type T.  For instance the Uniform(0.0, 1.0) is Float64.  Using the statistical style, we can add, multiply, divide them as if they were values of type Float64.","category":"page"},{"location":"model/","page":"Modeling","title":"Modeling","text":"x3 = x1 .+ x2","category":"page"},{"location":"model/","page":"Modeling","title":"Modeling","text":"Note x3 is a random variable.","category":"page"},{"location":"model/","page":"Modeling","title":"Modeling","text":"This includes inequalities:","category":"page"},{"location":"model/","page":"Modeling","title":"Modeling","text":"p = x3 .> 1.0","category":"page"},{"location":"model/","page":"Modeling","title":"Modeling","text":"julia> randsample(p)\nfalse","category":"page"},{"location":"model/","page":"Modeling","title":"Modeling","text":"A particularly useful case is that primitive distributions which take parameters of type T, also accept RandVar with elemtype T","category":"page"},{"location":"model/","page":"Modeling","title":"Modeling","text":"n = Normal.(x3, 1.0)","category":"page"},{"location":"model/","page":"Modeling","title":"Modeling","text":"Suppose you write your own function which take Float64s as input:","category":"page"},{"location":"model/","page":"Modeling","title":"Modeling","text":"myfunc(x::Float64, y::Float64) = (x * y)^2","category":"page"},{"location":"model/","page":"Modeling","title":"Modeling","text":"We can't automatically apply myfunc to random variables; it will cause a method error","category":"page"},{"location":"model/","page":"Modeling","title":"Modeling","text":"julia> myfunc(x1, x2)\nERROR: MethodError: no method matching myfunc...","category":"page"},{"location":"model/","page":"Modeling","title":"Modeling","text":"However this is easily remedied with the function lift:","category":"page"},{"location":"model/","page":"Modeling","title":"Modeling","text":"pw(myfunc, x1, x2)","category":"page"},{"location":"model/","page":"Modeling","title":"Modeling","text":"Or simply:","category":"page"},{"location":"model/","page":"Modeling","title":"Modeling","text":"myfunc.(x1, x2)","category":"page"},{"location":"model/#Explicit-Style","page":"Modeling","title":"Explicit Style","text":"","category":"section"},{"location":"model/","page":"Modeling","title":"Modeling","text":"The above style is convenient but has a few limitations and it hides a lot of the machinery. To create random variables in the explicit style, create a normal Julia function that takes as input","category":"page"},{"location":"model/","page":"Modeling","title":"Modeling","text":"For instance, to define a bernoulli distribution in explicit style:","category":"page"},{"location":"model/","page":"Modeling","title":"Modeling","text":"x_(ω) = @~ StdNormal{Float64}()(ω) > 0.5","category":"page"},{"location":"model/","page":"Modeling","title":"Modeling","text":"x_ is just a normal julia function.  ","category":"page"},{"location":"model/","page":"Modeling","title":"Modeling","text":"All of the primitive distributions can be used in explicit style by passing the rng object as the first parameter (type constraints are added just to show that the return values are not random variables but elements.  But don't add them to your own code! It will prevent automatic differentiation based inference procedures from working): ","category":"page"},{"location":"model/","page":"Modeling","title":"Modeling","text":"function x_(ω)\n  if Bernoulli(ω, 0.5, Bool)::Bool\n    normal(ω, 0.0, 1.0)::Float64\n  else Bernoulli(ω, 0.5, Bool)\n    betarv(ω, 2.0, 2.0)::Float64\n  end\nend","category":"page"},{"location":"model/","page":"Modeling","title":"Modeling","text":"Statistical style and functional style can be combined naturally. For example:","category":"page"},{"location":"model/","page":"Modeling","title":"Modeling","text":"x(ω) = (@~ Bernoulli(ω)) > 0.5 ? StdUniform(ω)^2 : sqrt.(StdUniform(ω))\ny = Normal(0.0, 1.0)\nz = x .+ y","category":"page"},{"location":"model/#Random-Variable-Families","page":"Modeling","title":"Random Variable Families","text":"","category":"section"},{"location":"model/","page":"Modeling","title":"Modeling","text":"Often we want to parameterize a random variable.  To do this we create functions which return random variables. For example, we can make a Uniform distribution family (without using Distributions.jl) by defining a function which maps a and b to a random variable","category":"page"},{"location":"model/","page":"Modeling","title":"Modeling","text":"\"Uniform distribution between `a` and `b`\"\n\nunif(a, b) = StdUniform{Float64}() .* (b - a) + b  \n\n\n# x is uniformly distributed between 10 and 20\nx = unif(10, 20)","category":"page"},{"location":"model/","page":"Modeling","title":"Modeling","text":"And hence if we wanted to create a method that created independent uniformly distributed random variables, we could do it like so:","category":"page"},{"location":"model/","page":"Modeling","title":"Modeling","text":"unif2(a,b) =~ rng -> rand(rng) * (b - a) + a\n\n# x is distributed between 30 and 40 (and independent of y)\nx = unif2(30, 40)\n\n# y is distributed between 30 and 40 (and independent of x)\ny = unif2(30, 40)","category":"page"},{"location":"soft/#Soft-Execution","page":"Soft Execution","title":"Soft Execution","text":"","category":"section"},{"location":"soft/","page":"Soft Execution","title":"Soft Execution","text":"note: Note\nTLDR: For inference problems which are continuous or high dimensional, use soft predicates to use more efficient inference routines.==ₛ\n>ₛ\n>=ₛ\n<=ₛ\n<ₛSoft predicates are supported (and required) by inference algorithms: SSMH, HMCFAST, NUTS, Replica.If the values x and y are not standard numeric types you will need to define a notion of distance (even if they are, you may want to wrap them and define a distance for this type).  Override Omega.d for the relevant typesOmega.d(x, y)","category":"page"},{"location":"soft/#Relaxation","page":"Soft Execution","title":"Relaxation","text":"","category":"section"},{"location":"soft/","page":"Soft Execution","title":"Soft Execution","text":"In Omega you condition on predicates. A predicate is any function whose domain is Boolean. These are sometimes called indicator functions or characteristic functions. In particular, in Omega we condition on Bool valued random variables:","category":"page"},{"location":"soft/","page":"Soft Execution","title":"Soft Execution","text":"x = normal(0.0, 1.0)\ny = x == 1.0\nrand(y)","category":"page"},{"location":"soft/","page":"Soft Execution","title":"Soft Execution","text":"From this perspective, conditioning means to solve a constraint. It can be difficult to solve these constraints exactly, and so Omega supports softened constraints to make inference more tractable.","category":"page"},{"location":"soft/","page":"Soft Execution","title":"Soft Execution","text":"To soften predicates, use soft counterparts to primitive predicates. Suppose we construct a random variable of the form x == y. In the soft version we would write x ==ₛ y (or softeq(x, y)).","category":"page"},{"location":"soft/","page":"Soft Execution","title":"Soft Execution","text":"julia> x = normal(0.0, 1.0)\njulia> y = x ==ₛ 1.0\njulia> rand(y)\nϵ:-47439.72956833765","category":"page"},{"location":"soft/","page":"Soft Execution","title":"Soft Execution","text":"note: Note\nIn the Julia REPL and most IDEs ==ₛ is constructed by typing ==\\_s [tab].","category":"page"},{"location":"soft/","page":"Soft Execution","title":"Soft Execution","text":"Softened predicates return values in unit interval [0, 1] as opposed to a simply true or false. Intuitively, 1 corresponds to true, and a high value (such as 0.999) corresonds to \"nearly true\". In practice, we encode this number in log scale [-Inf, 0] for numerical reasons. Mathematicallty, soft predicates they have the form:","category":"page"},{"location":"soft/","page":"Soft Execution","title":"Soft Execution","text":"k_alpha(rho(x y))","category":"page"},{"location":"soft/","page":"Soft Execution","title":"Soft Execution","text":"If rho(x y) denotes a notion of distance between x and y. Distances are determined by the method Omega.d","category":"page"},{"location":"soft/","page":"Soft Execution","title":"Soft Execution","text":"Omega.d","category":"page"},{"location":"soft/","page":"Soft Execution","title":"Soft Execution","text":"Rather than output values of type Float64, soft predicate output values of type SoftBool.","category":"page"},{"location":"soft/","page":"Soft Execution","title":"Soft Execution","text":"SoftBool","category":"page"},{"location":"soft/#Distances-and-Kernels","page":"Soft Execution","title":"Distances and Kernels","text":"","category":"section"},{"location":"soft/","page":"Soft Execution","title":"Soft Execution","text":"Omega has a number of built-in kernels:","category":"page"},{"location":"soft/","page":"Soft Execution","title":"Soft Execution","text":"kse\nkf1\nkpareto","category":"page"},{"location":"soft/","page":"Soft Execution","title":"Soft Execution","text":"By default, the squared exponential kernel kse is used with a default temperature parameter. The method withkernel can be used to choose which kernel is being applied within the context of a soft boolean operator.","category":"page"},{"location":"soft/","page":"Soft Execution","title":"Soft Execution","text":"withkernel","category":"page"},{"location":"cheatsheet/#Cheat-Sheet","page":"Cheat Sheet","title":"Cheat Sheet","text":"","category":"section"},{"location":"cheatsheet/#Core-Functions","page":"Cheat Sheet","title":"Core Functions","text":"","category":"section"},{"location":"cheatsheet/","page":"Cheat Sheet","title":"Cheat Sheet","text":"The major functions that you will use in Omega are:","category":"page"},{"location":"cheatsheet/","page":"Cheat Sheet","title":"Cheat Sheet","text":"~x : that is equal in distribution to x but conditionally independent given parents\ncond(x, y) : condition random variable x on condition y\ncond(ω, ab) : condition random variable that contains statement by force ab to be true]\nrand(x, n; alg = Alg) : n samples from (possibly conditioned) random variable x using algorithm ALG\nreplace(x, θold => θnew) : causal intervention in random variable\nrid(x, θ) : random interventional distribution of x given θ  \nrcd(x, θ) or x ∥ θ  : random conditional distribution of x given θ","category":"page"},{"location":"cheatsheet/#Terminology","page":"Cheat Sheet","title":"Terminology","text":"","category":"section"},{"location":"cheatsheet/","page":"Cheat Sheet","title":"Cheat Sheet","text":"Causal Inference:\nConditioning: Restricts a RandVar to be consistent with a predicate.  Conceptually, conditioning is the mechanism to add knowledge (observations, declarative facts, etcs) to a model.  \nIntervention: A change to a model.  Interventions support counterfactual \"what if\" questions. \nLift: To lift a function means to construct a new function that transforms random variables.\nModel: A collection of Random Variables.\nPrior: Unconditioned distribution.  In Bayesian inference terms, prior to having observed data\nPosterior: Technically identical to conditional distribution.  The term posterior is used commonly in the context of Bayesian inference where the conditional distribution is having observed more data.\nRandom Variable: a random variable is one kind of representation of a probability distribution.\nRealization (or outcome) space: Space (or type) of values that a random variable can take.  Since Random Variable are functions, technically this is its domain.  In Omega: elemtype(x) is its realization space \nRealization of a random variable: a value in the realization space, typically understood to be drawn according to its distribution.  In Omega, the result of rand(x) is a realizataion of x\nProbability Space: A tuple (Ω Σ μ) where  Ω is a sample space, Σ is a sigma algebra (roughly, set of all subsets of Ω, and μ is a probability measure).  In Omega: ","category":"page"},{"location":"cheatsheet/#Built-in-Distributions","page":"Cheat Sheet","title":"Built-in Distributions","text":"","category":"section"},{"location":"cheatsheet/","page":"Cheat Sheet","title":"Cheat Sheet","text":"bernoulli(w) boolbernoulli(w) betarv categorical constant exponential gammarv invgamma kumaraswamy logistic poisson normal uniform rademacher","category":"page"},{"location":"cheatsheet/#Built-in-Inference-Algorithms","page":"Cheat Sheet","title":"Built-in Inference Algorithms","text":"","category":"section"},{"location":"cheatsheet/","page":"Cheat Sheet","title":"Cheat Sheet","text":"RejectionSample MI SSMH SSMHDrift HMC HMCFAST","category":"page"},{"location":"correspondence/","page":"Preservation","title":"Preservation","text":"THe replace operator in Omega allows us to ask what-if questions. This raises thorny problems that are both philosophcal and technical. In particula, when we construct a counter-factual what-if scenario, what should be preserved from the \"real\" world to the counterfactual world?","category":"page"},{"location":"correspondence/","page":"Preservation","title":"Preservation","text":"Consider the following example:","category":"page"},{"location":"correspondence/","page":"Preservation","title":"Preservation","text":"coin = bernoulli(0.5, Bool)\nfunction x_(rng)\n  coin_ = coin(rng)\n  if coin\n    @show b = normal(rng, 0, 1)\n  else\n    @show b = normal(rng, 0, 1)\n  end\n  (coin = coin_, b = b)\nend\nx =~ x_","category":"page"},{"location":"correspondence/","page":"Preservation","title":"Preservation","text":"Let's draw a sample where y is false","category":"page"},{"location":"correspondence/","page":"Preservation","title":"Preservation","text":"rand(x, )","category":"page"},{"location":"correspondence/","page":"Preservation","title":"Preservation","text":"In a counterfactual world, we replace force y to be true","category":"page"},{"location":"correspondence/","page":"Preservation","title":"Preservation","text":"xnew = replace(x, y => true)","category":"page"},{"location":"correspondence/","page":"Preservation","title":"Preservation","text":"label(x, nm) =~ w -> (println(\"in $nm\"); x(w))\nxsum = label(xnew, \"xnew\") + label(x, \"x\")","category":"page"},{"location":"callbacks/#Callbacks","page":"Callbacks","title":"Callbacks","text":"","category":"section"},{"location":"callbacks/","page":"Callbacks","title":"Callbacks","text":"Omega uses Lenses and Callbacks to support queries such as:","category":"page"},{"location":"callbacks/","page":"Callbacks","title":"Callbacks","text":"Time left until the simulation end\nConvergence properties of the Markov Chains\nPeriodically saving results to disk","category":"page"},{"location":"callbacks/","page":"Callbacks","title":"Callbacks","text":"Each inference procedure exports some lenses. Currently these are of the form InferenceAlgLoop.  For example, the inference procedureSSMH has SSMHLoop lens called after each sample.","category":"page"},{"location":"callbacks/#Usage","page":"Callbacks","title":"Usage","text":"","category":"section"},{"location":"callbacks/","page":"Callbacks","title":"Callbacks","text":"using Callbacks, Lens\nx = ~ ω -> (sleep(0.001); normal(ω, 0, 1))\n@leval Loop => showprogress(10000) rand(x, 10000) ","category":"page"},{"location":"callbacks/","page":"Callbacks","title":"Callbacks","text":"using Omega.Inference: SSMHLoop\nx =~ ω -> (sleep(0.001); normal(ω, 0, 1))\n@leval SSMHLoop => plotloss() rand(x, x >ₛ 0.0, 10000; alg = SSMH)\n@leval SSMHLoop => default_cbs(10000) rand(x, x >ₛ 0.0, 10000; alg = SSMH)","category":"page"},{"location":"callbacks/#Default-Callbacks","page":"Callbacks","title":"Default Callbacks","text":"","category":"section"},{"location":"callbacks/","page":"Callbacks","title":"Callbacks","text":"default_cbs(n) returns a callback that displays a bunch of information likely to be useful, such as processbar, the likelihood, etc.  It takes as input n, the number of samples:","category":"page"},{"location":"callbacks/","page":"Callbacks","title":"Callbacks","text":"Example usage:","category":"page"},{"location":"callbacks/","page":"Callbacks","title":"Callbacks","text":"using Omega\nx = ω -> (sleep(0.001); normal(ω, 0, 1))\n@leval SSMHLoop => default_cbs(10000) rand(x, x >ₛ 0.0, 10000; alg = SSMH)","category":"page"},{"location":"internals/overview/#Omega-Internals","page":"Omega Internals","title":"Omega Internals","text":"","category":"section"},{"location":"internals/overview/","page":"Omega Internals","title":"Omega Internals","text":"Omega is a library for causal and probabilistic inference in Julia.  It shares many characteristics with other probabilistic languages, such as Pyro, Gen, Stan, and Turing, but has a few important differences.  At a high level, the salient properties of Omega are that:","category":"page"},{"location":"internals/overview/","page":"Omega Internals","title":"Omega Internals","text":"<!– The conceptual model of Omega could be summarized as follows: –>","category":"page"},{"location":"internals/overview/#Random-Variables","page":"Omega Internals","title":"Random Variables","text":"","category":"section"},{"location":"internals/overview/","page":"Omega Internals","title":"Omega Internals","text":"A very important type of object in Omega is a random variable.  The simplest kind of random variable is a primitive random variable.  There is an infintie set of primitive variables, that are all mutually independent.  Random variables in this set can be constructed using ~.  For example:","category":"page"},{"location":"internals/overview/","page":"Omega Internals","title":"Omega Internals","text":"ID = 1\nX = ID ~ StdUniform{Float64}()","category":"page"},{"location":"internals/overview/","page":"Omega Internals","title":"Omega Internals","text":"StdUniform{Flaot64} is a singleton type – it has a single element StdUniform{Float64}().","category":"page"},{"location":"internals/overview/","page":"Omega Internals","title":"Omega Internals","text":"A random variable in Omega is a function of the form","category":"page"},{"location":"internals/overview/","page":"Omega Internals","title":"Omega Internals","text":"X  Omega to T","category":"page"},{"location":"internals/overview/","page":"Omega Internals","title":"Omega Internals","text":"In Julia, a random variable is any function X such that X(\\omega::AbstractΩ) is well-defined, that is, the method exists, and X(\\omega::AbstractΩ) for all \\omega::AbstractΩ is well-defined.","category":"page"},{"location":"internals/overview/","page":"Omega Internals","title":"Omega Internals","text":"For those familiar with other probabilistic programming languages, the conceptual differences with Omega are that:","category":"page"},{"location":"internals/overview/","page":"Omega Internals","title":"Omega Internals","text":"Omega random variables are pure functions\n","category":"page"},{"location":"internals/overview/#Patterns","page":"Omega Internals","title":"Patterns","text":"","category":"section"},{"location":"internals/overview/","page":"Omega Internals","title":"Omega Internals","text":"μ = ~ Normal(0, 1)\nX1 = Normal(μ, 1)\nX2 = Normal(μ, 1)\nX3 = Normal(μ, 1)","category":"page"},{"location":"internals/overview/#Sampling","page":"Omega Internals","title":"Sampling","text":"","category":"section"},{"location":"internals/overview/","page":"Omega Internals","title":"Omega Internals","text":"Unlike other PPLs, random variables in Omega are not smaplers themselves, per-se.  They can be sampled from, using randsample.","category":"page"},{"location":"internals/overview/","page":"Omega Internals","title":"Omega Internals","text":"X = ID ~ StdUniform{Float64}()\nrandsample(X)","category":"page"},{"location":"internals/overview/#Distribution-Families","page":"Omega Internals","title":"Distribution Families","text":"","category":"section"},{"location":"internals/overview/#Probabilistic-Models","page":"Omega Internals","title":"Probabilistic Models","text":"","category":"section"},{"location":"internals/overview/","page":"Omega Internals","title":"Omega Internals","text":"In Omega, there is no explicit notion of a probabilistic model, there are only random variables. Conceptually, it can be useful to think of a probabilsitic model as a collection of random variables.","category":"page"},{"location":"internals/overview/#Independence-and-Conditional-Independence","page":"Omega Internals","title":"Independence and Conditional Independence","text":"","category":"section"},{"location":"internals/overview/","page":"Omega Internals","title":"Omega Internals","text":"When constructing a probabilistic model, it's common to want to:","category":"page"},{"location":"internals/overview/","page":"Omega Internals","title":"Omega Internals","text":"Construct multiple random variables that are \n","category":"page"},{"location":"internals/overview/#Conditioning","page":"Omega Internals","title":"Conditioning","text":"","category":"section"},{"location":"internals/overview/","page":"Omega Internals","title":"Omega Internals","text":"In Omega, conditioning is a process that transforms a random variable into a new one.","category":"page"},{"location":"internals/overview/","page":"Omega Internals","title":"Omega Internals","text":"Conditioning is performed by a function cnd, which naturally has the type:","category":"page"},{"location":"internals/overview/","page":"Omega Internals","title":"Omega Internals","text":"cnd  (Omega to T) times (Omega to Bool) to (Omega to T)","category":"page"},{"location":"internals/overview/#Likelihood-free-inference","page":"Omega Internals","title":"Likelihood-free inference","text":"","category":"section"},{"location":"internals/overview/#Likelihood-based-inference","page":"Omega Internals","title":"Likelihood-based inference","text":"","category":"section"},{"location":"internals/overview/#Higher-order-Inference","page":"Omega Internals","title":"Higher-order Inference","text":"","category":"section"},{"location":"internals/overview/#Interventnions","page":"Omega Internals","title":"Interventnions","text":"","category":"section"},{"location":"#Omega.jl","page":"Home","title":"Omega.jl","text":"","category":"section"},{"location":"","page":"Home","title":"Home","text":"Omega.jl is a programming language for causal and probabilistic reasoning. It was developed by Zenna Tavares with help from Javier Burroni, Edgar Minasyan, Xin Zhang, Rajesh Ranganath and Armando Solar Lezama.","category":"page"},{"location":"#Quick-Start","page":"Home","title":"Quick Start","text":"","category":"section"},{"location":"","page":"Home","title":"Home","text":"Omega is built in Julia.  You can easily install it from a Julia repl with:","category":"page"},{"location":"","page":"Home","title":"Home","text":"] add Omega","category":"page"},{"location":"","page":"Home","title":"Home","text":"To use Omega, start with:","category":"page"},{"location":"","page":"Home","title":"Home","text":"julia> using Omega","category":"page"},{"location":"","page":"Home","title":"Home","text":"With that, see the Tutorial for a run through of the main features of Omega. ","category":"page"},{"location":"#Contribute","page":"Home","title":"Contribute","text":"","category":"section"},{"location":"","page":"Home","title":"Home","text":"We want your contributions!","category":"page"},{"location":"","page":"Home","title":"Home","text":"Probabilistic models","category":"page"},{"location":"","page":"Home","title":"Home","text":"Please add probabilistic models and model families to https://github.com/zenna/OmegaModels.jl","category":"page"},{"location":"","page":"Home","title":"Home","text":"Inference procedures","category":"page"},{"location":"#Citation","page":"Home","title":"Citation","text":"","category":"section"},{"location":"","page":"Home","title":"Home","text":"If you use Omega, please cite Omega papers:","category":"page"},{"location":"","page":"Home","title":"Home","text":"If you use the causal inference features (replace), please cite:","category":"page"},{"location":"","page":"Home","title":"Home","text":"A Language for Counterfactual Generative Models","category":"page"},{"location":"","page":"Home","title":"Home","text":"@inproceedings{tavares2021language,\n  title={A language for counterfactual generative models},\n  author={Tavares, Zenna and Koppel, James and Zhang, Xin and Das, Ria and Solar-Lezama, Armando},\n  booktitle={International Conference on Machine Learning},\n  pages={10173--10182},\n  year={2021},\n  organization={PMLR}\n}","category":"page"},{"location":"","page":"Home","title":"Home","text":"Predicate exchange: Inference with declarative knowledge","category":"page"},{"location":"","page":"Home","title":"Home","text":"@inproceedings{tavares2019predicate,\n  title={Predicate exchange: Inference with declarative knowledge},\n  author={Tavares, Zenna and Burroni, Javier and Minasyan, Edgar and Solar-Lezama, Armando and Ranganath, Rajesh},\n  booktitle={International Conference on Machine Learning},\n  pages={6186--6195},\n  year={2019},\n  organization={PMLR}\n}\n","category":"page"},{"location":"","page":"Home","title":"Home","text":"The Random Conditional Distribution for Uncertain Distributional Properties","category":"page"},{"location":"","page":"Home","title":"Home","text":"@article{tavares2019rcd,\n  title={The Random Conditional Distribution for Uncertain Distributional Properties},\n  author={Tavares, Zenna and Burroni, Javier and Minaysan, Edgar and Ranganath, Rajesh and Lezama, Armando Solar},\n  journal={arXiv},\n  year={2019}\n}","category":"page"},{"location":"#Acknowledgements","page":"Home","title":"Acknowledgements","text":"","category":"section"},{"location":"","page":"Home","title":"Home","text":"Omega leans heavily on the hard work of many packages and the Julia community as a whole.","category":"page"},{"location":"#Index","page":"Home","title":"Index","text":"","category":"section"},{"location":"","page":"Home","title":"Home","text":"","category":"page"},{"location":"","page":"Home","title":"Home","text":"","category":"page"},{"location":"inferencealgorithms/#Built-in-Inference-Algorithms","page":"Sampling Algorithms","title":"Built-in Inference Algorithms","text":"","category":"section"},{"location":"inferencealgorithms/","page":"Sampling Algorithms","title":"Sampling Algorithms","text":"Omega comes with a number of built in inference algorithms. You can of course develop your own.","category":"page"},{"location":"inferencealgorithms/#Choosing-a-Sampling-Algorithm","page":"Sampling Algorithms","title":"Choosing a Sampling Algorithm","text":"","category":"section"},{"location":"inferencealgorithms/","page":"Sampling Algorithms","title":"Sampling Algorithms","text":"The appropriate sampling algorithm depends on the kind of model.","category":"page"},{"location":"inferencealgorithms/","page":"Sampling Algorithms","title":"Sampling Algorithms","text":"If your model is not conditioned, or the conditions are not very restricting, use RejectionSample\nIf your model is finite dimensional, continuous and unimodal use NUTS\nIf your model is finite dimensional, continuous and multimodal use Replica with NUTS\nIf your model is a mixture of discrete and continuous, or not of finite dimension, use SSMH or Replica with SSMH","category":"page"},{"location":"inferencealgorithms/#Conditional-Sampling","page":"Sampling Algorithms","title":"Conditional Sampling","text":"","category":"section"},{"location":"inferencealgorithms/","page":"Sampling Algorithms","title":"Sampling Algorithms","text":"Conditional sampling is done with rand and the algorithm are selected ","category":"page"},{"location":"inferencealgorithms/","page":"Sampling Algorithms","title":"Sampling Algorithms","text":"RejectionSample\nSSMH\nNUTS\nHMCFAST","category":"page"}]
}
